import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

/**
 * The Goal of TP5 is to be able to compute an approximative value of Pi . To do
 * so we were asked to use the Method of Monte - Carlo:
 * 
 * The method of Monte Carlo says in we generate a point in a 2 dimensional
 * plane, only a fourth of those points will land in a carter of a circle, said
 * said differently : only a 1/4 of the total generated points will land in the
 * area of Pi/4
 * 
 * Link for a detailed representation of the MonteCarlo method :
 * http://http://therese.eveilleau.pagesperso-orange.fr/pages/truc_mat/textes/
 * monte_carlo.htm (Link visited for the last time : 08/10/2016)
 */

public class TP5 {
	/**
	 * In the TP5 our mapper uses an IntWritable as an Entry Key,and a
	 * {@link Point2DWritable} as an Entry Value, and gives an IntWritable and a
	 * {@link Point2DWritable}.
	 *
	 */
	public static class TP5Mapper extends Mapper<IntWritable, Point2DWritable, IntWritable, Point2DWritable> {

		/*
		 * Here our Method map of the Mapper will just write the Keys and Values
		 * given in the Entry. Those keys, values will be given to the mapper by
		 * the RandomPointInputFormat. Look further in the main.
		 * 
		 * N.B: For more details, Check the comments on RandomPointInputFormat.
		 */

		public void map(IntWritable key, Point2DWritable value, Context context)
				throws IOException, InterruptedException {

			context.write(key, value);

		}
	}

	/**
	 * In the TP5 our reducer uses an IntWritable as an Entry Key,and a
	 * {@link Point2DWritable} as an Entry Value, and gives an IntWritable and a
	 * Text.
	 *
	 */

	public static class TP5Reducer extends Reducer<IntWritable, Point2DWritable, IntWritable, Text> {

		/*
		 * Here our reduce method will do all the necessary work to compute an
		 * approximative value of Pi, to do that we need two counters: -
		 * Valid_points : this will be used to calculate the number of points
		 * that landed in the area "Circle Quarter" - Number_Of_Points: this
		 * will be used to calculate the number of points generated by 'ALL' the
		 * mappers.
		 * 
		 * For each Key received by the reducer, we sweep the list of points
		 * having the same key, and for each point we increment our
		 * Number_Of_Points by one and test is that point belongs to the "Circle
		 * Quarter" . Thus we test for each point (x,y) with x belongs to[0,1[
		 * and y belongs to [0,1[ : (square of x) + (square of y) < 1. If that's
		 * true, that would mean the point belongs the "Circle Quarter" and in
		 * that case we increment our Counter of Valid_Points by 1.
		 * 
		 * At the End we compute an Approximative value of Pi which will be
		 * equal to: [(How Many points were valid)/(How Many were generated)]*4
		 * And we write the result in File that will result.
		 */

		public void reduce(IntWritable key, Iterable<Point2DWritable> values, Context context)
				throws IOException, InterruptedException {

			Counter Valid_Points = context.getCounter("count", "ValidPoints");
			Counter Number_Of_Points = context.getCounter("Count", "NumberOfPoints");

			for (Point2DWritable value : values) {

				Number_Of_Points.increment(1);

				if (((Math.pow(value.getX(), 2)) + (Math.pow(value.getY(), 2))) < 1) {
					Valid_Points.increment(1);
				}
			}
			double ptsV = Valid_Points.getValue();
			double nbrpts = Number_Of_Points.getValue();
			double result = (ptsV / nbrpts) * 4;
			System.out.println(result);
			String str = "We have generated : " + nbrpts
					+ " Points and that gives us an approximative value of Pi that is :" + result;
			context.write(key, new Text(str));

		}

	}

	/**
	 * In our main, we need to get the 3 arguments needed: the number of points
	 * Max by each mapper, The number of Mappers, and the file that we will
	 * write our result in.
	 *
	 * Plus we need to change the OutPutValue and OutPutKey of the mappers to be
	 * adequate to what we used before in our Class Mapper. Most Importantly we
	 * need to specify that our InputFormat will be RandomPointInputFormat,
	 * specifying that, it will call automatically the methods of InputFormat :
	 * getSplits(), and createRecordReader() which we implemented in our
	 * RandomPointInputFormat.
	 */
	public static void main(String[] args) throws Exception {
		Configuration conf = new Configuration();

		conf.set("MaxPoints", args[0]);
		conf.set("NumberOfSplits", args[1]);

		Job job = Job.getInstance(conf, "TP5");
		job.setNumReduceTasks(1);
		job.setJarByClass(TP5.class);
		job.setMapperClass(TP5Mapper.class);
		job.setMapOutputKeyClass(IntWritable.class);
		job.setMapOutputValueClass(Point2DWritable.class);
		job.setReducerClass(TP5Reducer.class);
		job.setOutputKeyClass(IntWritable.class);
		job.setOutputValueClass(Text.class);
		job.setOutputFormatClass(TextOutputFormat.class);
		job.setInputFormatClass(RandomPointInputFormat.class);
		FileOutputFormat.setOutputPath(job, new Path(args[2]));
		System.exit(job.waitForCompletion(true) ? 0 : 1);
	}
}
